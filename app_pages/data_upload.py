# import streamlit as st
# from components.milvus_mongo_insert import milvus_mongo_upload
# import pandas as pd


# def data_upload_page():
#     st.markdown("## ğŸ“Š æ•°æ®ä¸Šä¼ ä¸å¤„ç†")

#     # æ¨¡å‹é…ç½®å®‰å…¨è·å–
#     raw_model_config = st.session_state.get("model_config", {})
#     model_config = raw_model_config if isinstance(raw_model_config, dict) else {}
#     current_model = model_config.get("last_used_model", "")

#     if not current_model or not st.session_state.get("model_loaded", False):
#         st.warning("âš ï¸ å°šæœªåŠ è½½åµŒå…¥æ¨¡å‹ï¼")
#         st.info("ğŸ’¡ è¯·å…ˆåˆ° 'ğŸ¤– åµŒå…¥æ¨¡å‹ç®¡ç†' é¡µé¢åŠ è½½æ¨¡å‹ï¼Œç„¶åå†å›åˆ°æ­¤é¡µé¢è¿›è¡Œæ•°æ®å¤„ç†ã€‚")
#         col1, col2 = st.columns([3, 1])
#         with col1:
#             st.markdown("""
#             **ä¸ºä»€ä¹ˆéœ€è¦å…ˆåŠ è½½æ¨¡å‹ï¼Ÿ**
#             - æ–‡æœ¬å‘é‡åŒ–éœ€è¦ä½¿ç”¨åµŒå…¥æ¨¡å‹
#             - æ¨¡å‹åŠ è½½åå¯ä»¥å¤„ç†ä»»ä½•æ–‡æœ¬æ•°æ®
#             - ç»Ÿä¸€çš„æ¨¡å‹ç®¡ç†ç¡®ä¿é…ç½®ä¸€è‡´æ€§
#             """)
#         with col2:
#             if st.button("ğŸš€ å‰å¾€æ¨¡å‹ç®¡ç†", type="primary"):
#                 st.switch_page("ğŸ¤– åµŒå…¥æ¨¡å‹ç®¡ç†")
#                 st.rerun()
#         return

#     # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
#     st.markdown("### ğŸ¤– å½“å‰æ¨¡å‹çŠ¶æ€")
#     col1, col2 = st.columns([3, 1])
#     vp = st.session_state["components"]["vector_processor"]
#     with col1:
#         st.success(f"âœ… å·²åŠ è½½æ¨¡å‹: **{current_model}**")
#         model_info = vp.get_model_info()
#         if model_info:
#             st.info(f"ğŸ”¢ å‘é‡ç»´åº¦: {model_info.get('dimension', 'N/A')}")
#     with col2:
#         if st.button("ğŸ”„ åˆ‡æ¢æ¨¡å‹"):
#             st.info("ğŸ’¡ è¯·åˆ° 'ğŸ¤– åµŒå…¥æ¨¡å‹ç®¡ç†' é¡µé¢åˆ‡æ¢æ¨¡å‹")

#     st.markdown("---")

#     # æ•°æ®ä¸Šä¼ é€‰é¡¹
#     upload_method = st.radio(
#         "é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼",
#         ["ğŸ“ ä¸Šä¼ JSONæ–‡ä»¶", "âœï¸ æ‰‹åŠ¨è¾“å…¥JSONæ•°æ®", "ğŸ¯ ä½¿ç”¨ç¤ºä¾‹æ•°æ®"],
#         horizontal=True
#     )

#     json_data = None
#     if upload_method == "ğŸ“ ä¸Šä¼ JSONæ–‡ä»¶":
#         uploaded_file = st.file_uploader(
#             "é€‰æ‹©JSONæ–‡ä»¶",
#             type=['json', 'jsonl', 'txt'],
#             help="æ”¯æŒJSONã€JSONLæ ¼å¼æ–‡ä»¶ã€‚JSONæ ¼å¼ï¼š[{\"text\":\"å†…å®¹\"}]ï¼ŒJSONLæ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡"
#         )
#         if uploaded_file is not None:
#             try:
#                 file_content = uploaded_file.read().decode('utf-8')
#                 json_data = vp.parse_json_file(file_content)
#                 if not isinstance(json_data, list):
#                     json_data = [json_data]
#                 st.success(f"âœ… æˆåŠŸåŠ è½½ {len(json_data)} æ¡æ•°æ®")
#                 file_size = uploaded_file.size / 1024 / 1024
#                 st.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
#                 sample_item = json_data[0] if json_data else {}
#                 if isinstance(sample_item, dict):
#                     keys = list(sample_item.keys())
#                     keys_display = ', '.join(keys[:5])
#                     if len(keys) > 5:
#                         keys_display += '...'
#                     st.info(f"ğŸ” æ£€æµ‹åˆ°å­—æ®µ: {keys_display}")
#             except Exception as e:
#                 st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
#                 st.markdown("""
#                 **æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š**
#                 1. **æ ‡å‡†JSONæ•°ç»„**: `[{"text":"å†…å®¹1"}, {"text":"å†…å®¹2"}]`
#                 2. **JSONLæ ¼å¼**: æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
#                    ```
#                    {"text":"å†…å®¹1"}
#                    {"text":"å†…å®¹2"}
#                    ```
#                 3. **å•ä¸ªJSONå¯¹è±¡**: `{"text":"å†…å®¹"}`
#                 """)
#     elif upload_method == "âœï¸ æ‰‹åŠ¨è¾“å…¥JSONæ•°æ®":
#         json_text = st.text_area(
#             "è¾“å…¥JSONæ•°æ®",
#             height=200,
#             placeholder='[{"text":"åŠç”Ÿé•¿ä»¥å®¢ä¸ºå®¶ï¼Œç½¢ç›´åˆæ¥ç€šæµ·æ§ã€‚å§‹ä¿¡äººé—´è¡Œä¸å°½ï¼Œå¤©æ¶¯æ›´å¤æœ‰å¤©æ¶¯ã€‚"}]',
#             help="è¯·è¾“å…¥æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®"
#         )
#         if json_text.strip():
#             try:
#                 json_data = vp.parse_json_file(json_text)
#                 if not isinstance(json_data, list):
#                     json_data = [json_data]
#                 st.success(f"âœ… æˆåŠŸè§£æ {len(json_data)} æ¡æ•°æ®")
#             except Exception as e:
#                 st.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
#     elif upload_method == "ğŸ¯ ä½¿ç”¨ç¤ºä¾‹æ•°æ®":
#         sample_data = [
#             {"text": "åŠç”Ÿé•¿ä»¥å®¢ä¸ºå®¶ï¼Œç½¢ç›´åˆæ¥ç€šæµ·æ§ã€‚å§‹ä¿¡äººé—´è¡Œä¸å°½ï¼Œå¤©æ¶¯æ›´å¤æœ‰å¤©æ¶¯ã€‚"},
#             {"text": "æ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸€æ—¥çœ‹å°½é•¿å®‰èŠ±ã€‚"},
#             {"text": "å±±é‡æ°´å¤ç–‘æ— è·¯ï¼ŒæŸ³æš—èŠ±æ˜åˆä¸€æ‘ã€‚"},
#             {"text": "æµ·å†…å­˜çŸ¥å·±ï¼Œå¤©æ¶¯è‹¥æ¯”é‚»ã€‚"},
#             {"text": "è½çº¢ä¸æ˜¯æ— æƒ…ç‰©ï¼ŒåŒ–ä½œæ˜¥æ³¥æ›´æŠ¤èŠ±ã€‚"},
#             {"text": "ä¼šå½“å‡Œç»é¡¶ï¼Œä¸€è§ˆä¼—å±±å°ã€‚"},
#             {"text": "é‡‡èŠä¸œç¯±ä¸‹ï¼Œæ‚ ç„¶è§å—å±±ã€‚"},
#             {"text": "æ˜æœˆå‡ æ—¶æœ‰ï¼ŒæŠŠé…’é—®é’å¤©ã€‚"}
#         ]
#         json_data = sample_data
#         st.info(f"ğŸ¯ ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼Œå…± {len(json_data)} æ¡å¤è¯—è¯")

#     # æ•°æ®é¢„è§ˆå’Œå¤„ç†
#     if json_data:
#         st.markdown("### ğŸ“‹ æ•°æ®é¢„è§ˆ")
#         col1, col2, col3 = st.columns(3)
#         with col1:
#             st.metric("æ•°æ®æ¡æ•°", len(json_data))
#         with col2:
#             total_chars = sum(len(str(item)) for item in json_data)
#             st.metric("æ€»å­—ç¬¦æ•°", f"{total_chars:,}")
#         with col3:
#             avg_length = total_chars / len(json_data) if json_data else 0
#             st.metric("å¹³å‡é•¿åº¦", f"{avg_length:.1f}")
#         df_preview = pd.DataFrame(json_data[:10])
#         st.dataframe(df_preview, use_container_width=True)
#         if len(json_data) > 10:
#             st.info(f"æ˜¾ç¤ºå‰10æ¡æ•°æ®ï¼Œæ€»å…±{len(json_data)}æ¡")

#         # å‘é‡åŒ–å¤„ç†
#         st.markdown("### ğŸš€ å‘é‡åŒ–å¤„ç†")
#         col1, col2 = st.columns([3, 1])
#         with col1:
#             st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æ–‡æœ¬å‘é‡åŒ–å¤„ç†ï¼Œå¤„ç†åçš„æ•°æ®å¯ä»¥ä¿å­˜åˆ°Milvusæ•°æ®åº“ä¸­æ°¸ä¹…å­˜å‚¨")
#         with col2:
#             process_button = st.button("ğŸš€ å¼€å§‹å‘é‡åŒ–å¤„ç†å¹¶æŒä¹…åŒ–", type="primary")
#         if process_button:
#             progress_bar = st.progress(0)
#             status_text = st.empty()
#             try:
#                 status_text.text("ğŸ“Š æ­£åœ¨å¤„ç†æ–‡æœ¬æ•°æ®...")
#                 progress_bar.progress(30)
#                 texts, vectors, metadata = vp.process_json_data(json_data)
#                 embedding_dim = vectors.shape[1]
#                 progress_bar.progress(60)
#                 milvus_manager = st.session_state["components"]["milvus_manager"]
#                 collection = milvus_manager.collection

#                 # æ£€æŸ¥é›†åˆç»´åº¦é€»è¾‘è‡ªåŠ¨é‡å»º
#                 need_rebuild = False
#                 if collection:
#                     milvus_dim = None
#                     for f in collection.schema.fields:
#                         if 'dim' in f.params:
#                             milvus_dim = int(f.params['dim'])
#                             break
#                     if milvus_dim is None:
#                         st.error("âŒ å½“å‰é›†åˆschemaæœªæ‰¾åˆ°å‘é‡ç»´åº¦(dim)å®šä¹‰ï¼Œè¯·æ£€æŸ¥é›†åˆå­—æ®µï¼")
#                         progress_bar.empty()
#                         status_text.empty()
#                         return
#                     if milvus_dim != embedding_dim:
#                         status_text.text(f"â— æ£€æµ‹åˆ°æ¨¡å‹å‘é‡ç»´åº¦({embedding_dim})ä¸Milvusé›†åˆ({milvus_dim})ä¸ä¸€è‡´ï¼Œè‡ªåŠ¨é‡å»ºé›†åˆ...")
#                         milvus_manager.delete_collection()
#                         need_rebuild = True
#                 else:
#                     need_rebuild = True

#                 if need_rebuild:
#                     success = milvus_manager.create_collection(embedding_dim)
#                     if not success:
#                         st.error("âŒ Milvusé›†åˆé‡å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œé…ç½®ä¿¡æ¯ï¼")
#                         progress_bar.empty()
#                         status_text.empty()
#                         return
#                     status_text.text(f"âœ… Milvusé›†åˆå·²é‡å»ºï¼Œç»´åº¦: {embedding_dim}")
#                     progress_bar.progress(80)
#                     # ä¿è¯collectionå¯¹è±¡ä¸ºæœ€æ–°
#                     milvus_manager.get_collection_object()

#                 # ==== å¼ºåˆ¶æ¸…æ´—æ–‡æœ¬ï¼Œåªä¿ç•™string ====
#                 texts_clean = [t[0] if isinstance(t, list) and len(t) > 0 else t for t in texts]
#                 texts_clean = [str(t) for t in texts_clean if isinstance(t, str)]

#                 # print("DEBUG texts_clean typeå‰5:", [(t, type(t)) for t in texts_clean[:5]])
#                 # print("DEBUG texts_cleanç»“æ„:", texts_clean[:5])

#                 # å¼€å§‹æ’å…¥æ•°æ®
#                 st.session_state.texts = texts
#                 st.session_state.vectors = vectors
#                 st.session_state.metadata = metadata
#                 st.session_state.data_loaded = True
#                 try:
#                     inserted_ids = milvus_mongo_upload(texts, vectors, metadata, milvus_dim=embedding_dim)
#                     progress_bar.progress(100)
#                     status_text.text(f"âœ… å‘é‡åŒ–åŠæŒä¹…åŒ–å®Œæˆï¼å·²æ’å…¥ {len(inserted_ids)} æ¡æ•°æ®ã€‚")
#                     st.success(f"ğŸ’¾ å‘é‡åŒ–å’ŒæŒä¹…åŒ–å®Œæˆï¼æˆåŠŸå¤„ç†å¹¶å†™å…¥ {len(inserted_ids)} æ¡æ–‡æœ¬æ•°æ®ã€‚")
#                 except Exception as e:
#                     progress_bar.progress(100)
#                     status_text.text("âš ï¸ å‘é‡åŒ–å®Œæˆï¼Œä½†æŒä¹…åŒ–å¤±è´¥")
#                     st.warning(f"âš ï¸ å‘é‡åŒ–å®Œæˆï¼Œä½†æ•°æ®æŒä¹…åŒ–å¤±è´¥: {e}")
#                     st.info("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°å†…å­˜ä¸­ï¼Œå¯ä»¥è¿›è¡Œæœç´¢å’Œèšç±»åˆ†æã€‚è¦å¯ç”¨æŒä¹…åŒ–ï¼Œè¯·æ£€æŸ¥Milvuså’ŒMongoDBè¿æ¥ã€‚")

#                 # æœç´¢å¼•æ“ã€èšç±»åˆ†æåŒæ­¥
#                 st.session_state.components['search_engine'].load_data(vectors, texts, metadata)
#                 st.session_state.components['search_engine'].set_vector_processor(vp)
#                 st.session_state.components['clustering_analyzer'].load_data(vectors, texts, metadata)
#                 st.success(f"ğŸ‰ å‘é‡åŒ–å®Œæˆï¼æˆåŠŸå¤„ç†äº† {len(texts)} æ¡æ–‡æœ¬")
#                 # ç»“æœç»Ÿè®¡ç•¥
#             except Exception as e:
#                 st.error(f"âŒ å‘é‡åŒ–å¤„ç†å¤±è´¥: {e}")
#                 st.exception(e)
#             finally:
#                 progress_bar.empty()
#                 status_text.empty()

import streamlit as st
from components.milvus_mongo_insert import milvus_mongo_upload
import pandas as pd
import numpy as np
import re
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
from collections import Counter


# ============================================
# æ•°æ®è´¨é‡éªŒè¯å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
# ============================================

@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœ"""
    is_valid: bool
    reason: str = ""
    quality_score: float = 0.0
    metrics: Dict[str, Any] = None


class TextQualityValidator:
    """æ–‡æœ¬è´¨é‡éªŒè¯å™¨ - Streamlitä¼˜åŒ–ç‰ˆ"""
    
    def __init__(
        self,
        min_length: int = 10,
        max_length: int = 10000,
        max_url_count: int = 3,
        max_special_char_ratio: float = 0.4,
        min_chinese_ratio: float = 0.05,
        enable_strict_mode: bool = False
    ):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            min_length: æœ€å°æ–‡æœ¬é•¿åº¦
            max_length: æœ€å¤§æ–‡æœ¬é•¿åº¦
            max_url_count: å…è®¸çš„æœ€å¤§URLæ•°é‡
            max_special_char_ratio: ç‰¹æ®Šå­—ç¬¦æœ€å¤§æ¯”ä¾‹
            min_chinese_ratio: ä¸­æ–‡å­—ç¬¦æœ€å°æ¯”ä¾‹
            enable_strict_mode: æ˜¯å¦å¯ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆæ›´ä¸¥æ ¼çš„è¿‡æ»¤è§„åˆ™ï¼‰
        """
        self.min_length = min_length
        self.max_length = max_length
        self.max_url_count = max_url_count
        self.max_special_char_ratio = max_special_char_ratio
        self.min_chinese_ratio = min_chinese_ratio
        self.enable_strict_mode = enable_strict_mode
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæé«˜æ€§èƒ½ï¼‰
        self.url_pattern = re.compile(
            r'https?://[^\s]+|www\.[^\s]+|\w+\.(com|cn|net|org|edu|gov|io|co)/[^\s]*',
            re.IGNORECASE
        )
        self.chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
        self.special_char_pattern = re.compile(r'[^\w\s\u4e00-\u9fff]')
        
        # åƒåœ¾æ¨¡å¼ï¼ˆæ ¹æ®ä½ çš„å®é™…æ•°æ®è°ƒæ•´ï¼‰
        self.garbage_patterns = [
            (r'(\.Shtml\s*){3,}', "é‡å¤HTMLåç¼€", 5),
            (r'(blog\.|5g\.|m\.|h5\.|www\.){8,}', "é‡å¤å­åŸŸå", 5),
            (r'(\d{5,}\s*){8,}', "å¤§é‡è¿ç»­æ•°å­—", 3),
            (r'(<[^>]+>\s*){5,}', "å¤§é‡HTMLæ ‡ç­¾", 4),
            (r'(FROM:|æ¥æº:|â€»|Â·){3,}', "é‡å¤å…ƒä¿¡æ¯æ ‡è®°", 3),
            (r'(Article/\d+|details/\d+|blog/\d+){5,}', "URLè·¯å¾„æ¨¡å¼", 4),
        ]
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        self.stats = {
            "total": 0,
            "accepted": 0,
            "rejected": 0,
            "reasons": Counter()
        }
    
    def validate(self, text: str) -> ValidationResult:
        """
        éªŒè¯å•ä¸ªæ–‡æœ¬
        
        Args:
            text: å¾…éªŒè¯æ–‡æœ¬
            
        Returns:
            ValidationResult: éªŒè¯ç»“æœå¯¹è±¡
        """
        self.stats["total"] += 1
        
        # åŸºç¡€æ£€æŸ¥
        if not text or not isinstance(text, str):
            self.stats["rejected"] += 1
            self.stats["reasons"]["ç©ºæ–‡æœ¬æˆ–ç±»å‹é”™è¯¯"] += 1
            return ValidationResult(False, "ç©ºæ–‡æœ¬æˆ–ç±»å‹é”™è¯¯")
        
        text = text.strip()
        text_length = len(text)
        
        # é•¿åº¦æ£€æŸ¥
        if text_length < self.min_length:
            self.stats["rejected"] += 1
            self.stats["reasons"][f"æ–‡æœ¬è¿‡çŸ­(<{self.min_length})"] += 1
            return ValidationResult(
                False, 
                f"æ–‡æœ¬è¿‡çŸ­({text_length} < {self.min_length})"
            )
        
        if text_length > self.max_length:
            self.stats["rejected"] += 1
            self.stats["reasons"][f"æ–‡æœ¬è¿‡é•¿(>{self.max_length})"] += 1
            return ValidationResult(
                False,
                f"æ–‡æœ¬è¿‡é•¿({text_length} > {self.max_length})"
            )
        
        # URLæ£€æŸ¥
        urls = self.url_pattern.findall(text)
        url_count = len(urls)
        if url_count > self.max_url_count:
            self.stats["rejected"] += 1
            self.stats["reasons"][f"é“¾æ¥è¿‡å¤š(>{self.max_url_count})"] += 1
            return ValidationResult(
                False,
                f"é“¾æ¥è¿‡å¤š({url_count} > {self.max_url_count})"
            )
        
        # ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹æ£€æŸ¥
        special_chars = len(self.special_char_pattern.findall(text))
        special_char_ratio = special_chars / text_length
        if special_char_ratio > self.max_special_char_ratio:
            self.stats["rejected"] += 1
            self.stats["reasons"]["ç‰¹æ®Šå­—ç¬¦è¿‡å¤š"] += 1
            return ValidationResult(
                False,
                f"ç‰¹æ®Šå­—ç¬¦è¿‡å¤š({special_char_ratio:.1%})"
            )
        
        # ä¸­æ–‡å­—ç¬¦æ£€æŸ¥
        chinese_chars = len(self.chinese_pattern.findall(text))
        chinese_char_ratio = chinese_chars / text_length
        if chinese_char_ratio < self.min_chinese_ratio:
            self.stats["rejected"] += 1
            self.stats["reasons"]["ä¸­æ–‡å†…å®¹ä¸è¶³"] += 1
            return ValidationResult(
                False,
                f"ä¸­æ–‡å†…å®¹ä¸è¶³({chinese_char_ratio:.1%})"
            )
        
        # åƒåœ¾æ¨¡å¼æ£€æµ‹
        for pattern, reason, weight in self.garbage_patterns:
            match = re.search(pattern, text)
            if match:
                self.stats["rejected"] += 1
                self.stats["reasons"][reason] += 1
                return ValidationResult(False, f"æ£€æµ‹åˆ°åƒåœ¾æ¨¡å¼: {reason}")
        
        # ä¸¥æ ¼æ¨¡å¼é¢å¤–æ£€æŸ¥
        if self.enable_strict_mode:
            # æ£€æŸ¥é‡å¤å­—ç¬¦
            if re.search(r'(.)\1{10,}', text):
                self.stats["rejected"] += 1
                self.stats["reasons"]["é‡å¤å­—ç¬¦"] += 1
                return ValidationResult(False, "åŒ…å«è¿‡å¤šé‡å¤å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯æ•°å­—å’Œç¬¦å·
            if chinese_chars < 5 and text_length > 20:
                self.stats["rejected"] += 1
                self.stats["reasons"]["æœ‰æ•ˆä¸­æ–‡ä¸è¶³"] += 1
                return ValidationResult(False, "æœ‰æ•ˆä¸­æ–‡å­—ç¬¦ä¸è¶³5ä¸ª")
        
        # è®¡ç®—è´¨é‡åˆ†æ•° (0-100)
        quality_score = self._calculate_quality_score(
            text_length, url_count, special_char_ratio, chinese_char_ratio
        )
        
        # é€šè¿‡éªŒè¯
        self.stats["accepted"] += 1
        return ValidationResult(
            True,
            "é€šè¿‡éªŒè¯",
            quality_score,
            {
                "length": text_length,
                "url_count": url_count,
                "special_ratio": special_char_ratio,
                "chinese_ratio": chinese_char_ratio
            }
        )
    
    def _calculate_quality_score(
        self, 
        length: int, 
        url_count: int, 
        special_ratio: float, 
        chinese_ratio: float
    ) -> float:
        """è®¡ç®—æ–‡æœ¬è´¨é‡åˆ†æ•°"""
        score = 100.0
        
        # é•¿åº¦åˆ†æ•° (ç†æƒ³é•¿åº¦50-500å­—ç¬¦)
        if length < 50:
            score -= (50 - length) * 0.2
        elif length > 500:
            score -= (length - 500) * 0.01
        
        # URLæƒ©ç½š
        score -= url_count * 5
        
        # ç‰¹æ®Šå­—ç¬¦æƒ©ç½š
        score -= special_ratio * 30
        
        # ä¸­æ–‡æ¯”ä¾‹å¥–åŠ±
        score += min(chinese_ratio * 20, 20)
        
        return max(0, min(100, score))
    
    def clean_text(self, text: str) -> str:
        """
        æ¸…æ´—æ–‡æœ¬
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…æ´—åçš„æ–‡æœ¬
        """
        if not isinstance(text, str):
            return ""
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # å¯é€‰ï¼šç§»é™¤æŸäº›ç‰¹å®šçš„åƒåœ¾å­—ç¬¦
        text = re.sub(r'[â€»Â·â†’â†â†‘â†“]', '', text)
        
        return text
    
    def get_stats_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        total = self.stats["total"]
        if total == 0:
            return {"message": "æš‚æ— æ•°æ®"}
        
        acceptance_rate = (self.stats["accepted"] / total) * 100
        
        return {
            "æ€»éªŒè¯æ•°": total,
            "é€šè¿‡æ•°": self.stats["accepted"],
            "æ‹’ç»æ•°": self.stats["rejected"],
            "é€šè¿‡ç‡": f"{acceptance_rate:.1f}%",
            "ä¸»è¦æ‹’ç»åŸå› ": dict(self.stats["reasons"].most_common(3))
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.stats = {
            "total": 0,
            "accepted": 0,
            "rejected": 0,
            "reasons": Counter()
        }


# ============================================
# æ‰¹é‡æ•°æ®å¤„ç†å‡½æ•°
# ============================================

def batch_validate_and_clean(
    json_data: List[Dict],
    validator: TextQualityValidator,
    show_progress: bool = True
) -> Tuple[List[Dict], List[Dict], Dict[str, Any]]:
    """
    æ‰¹é‡éªŒè¯å’Œæ¸…æ´—æ•°æ®
    
    Args:
        json_data: åŸå§‹JSONæ•°æ®åˆ—è¡¨
        validator: éªŒè¯å™¨å®ä¾‹
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
    Returns:
        (æœ‰æ•ˆæ•°æ®åˆ—è¡¨, æ— æ•ˆæ•°æ®åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯)
    """
    valid_data = []
    invalid_data = []
    
    if show_progress:
        progress_bar = st.progress(0)
        status_text = st.empty()
    
    total = len(json_data)
    
    for idx, item in enumerate(json_data):
        # æ£€æŸ¥æ•°æ®æ ¼å¼
        if not isinstance(item, dict):
            invalid_data.append({
                "item": item,
                "reason": "æ•°æ®æ ¼å¼é”™è¯¯ï¼šä¸æ˜¯å­—å…¸ç±»å‹"
            })
            continue
        
        # å°è¯•æŸ¥æ‰¾æ–‡æœ¬å­—æ®µï¼ˆæ”¯æŒ text, text1, content ç­‰å¸¸è§å­—æ®µåï¼‰
        text = None
        text_field = None
        for field in ["text", "text1", "content", "body", "message"]:
            if field in item:
                text = item[field]
                text_field = field
                break
        
        if text is None:
            invalid_data.append({
                "item": item,
                "reason": f"ç¼ºå°‘æ–‡æœ¬å­—æ®µï¼ˆæ£€æŸ¥äº†: text, text1, contentç­‰ï¼‰ã€‚å®é™…å­—æ®µ: {list(item.keys())}"
            })
            continue
        
        # æ¸…æ´—æ–‡æœ¬
        text = validator.clean_text(str(text))
        
        # éªŒè¯
        result = validator.validate(text)
        
        if result.is_valid:
            # æ›´æ–°æ–‡æœ¬ä¸ºæ¸…æ´—åçš„ç‰ˆæœ¬ï¼Œç»Ÿä¸€ä½¿ç”¨ "text" å­—æ®µ
            item_copy = item.copy()
            item_copy["text"] = text  # ç»Ÿä¸€å­—æ®µå
            if text_field != "text" and text_field in item_copy:
                del item_copy[text_field]  # åˆ é™¤åŸå­—æ®µåï¼ˆå¦‚æœä¸æ˜¯textï¼‰
            item_copy["_quality_score"] = result.quality_score
            item_copy["_original_field"] = text_field  # è®°å½•åŸå§‹å­—æ®µå
            valid_data.append(item_copy)
        else:
            invalid_data.append({
                "item": item,
                "reason": result.reason,
                "text_preview": text[:100] if text else "æ— æ–‡æœ¬"
            })
        
        # æ›´æ–°è¿›åº¦
        if show_progress and (idx + 1) % max(1, total // 20) == 0:
            progress = (idx + 1) / total
            progress_bar.progress(progress)
            status_text.text(
                f"æ­£åœ¨éªŒè¯æ•°æ®... {idx + 1}/{total} "
                f"(é€šè¿‡: {len(valid_data)}, æ‹’ç»: {len(invalid_data)})"
            )
    
    if show_progress:
        progress_bar.empty()
        status_text.empty()
    
    stats = validator.get_stats_summary()
    
    return valid_data, invalid_data, stats


# ============================================
# Streamlit ä¸»é¡µé¢å‡½æ•°
# ============================================

def data_upload_page():
    st.markdown("## ğŸ“¤ æ•°æ®ä¸Šä¼ ä¸å¤„ç†")

    # ===== åˆå§‹åŒ–éªŒè¯å™¨ =====
    if "validator" not in st.session_state:
        st.session_state.validator = TextQualityValidator(
            min_length=10,
            max_url_count=3,
            min_chinese_ratio=0.05,
            enable_strict_mode=False
        )

    # æ¨¡å‹é…ç½®å®‰å…¨è·å–
    raw_model_config = st.session_state.get("model_config", {})
    model_config = raw_model_config if isinstance(raw_model_config, dict) else {}
    current_model = model_config.get("last_used_model", "")

    if not current_model or not st.session_state.get("model_loaded", False):
        st.warning("âš ï¸ å°šæœªåŠ è½½åµŒå…¥æ¨¡å‹ï¼")
        st.info("ğŸ“Œ è¯·å…ˆåˆ° 'ğŸ”¥ åµŒå…¥æ¨¡å‹ç®¡ç†' é¡µé¢åŠ è½½æ¨¡å‹ï¼Œç„¶åå†å›åˆ°æ­¤é¡µé¢è¿›è¡Œæ•°æ®å¤„ç†ã€‚")
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown("""
            **ä¸ºä»€ä¹ˆéœ€è¦å…ˆåŠ è½½æ¨¡å‹ï¼Ÿ**
            - æ–‡æœ¬å‘é‡åŒ–éœ€è¦ä½¿ç”¨åµŒå…¥æ¨¡å‹
            - æ¨¡å‹åŠ è½½åå¯ä»¥å¤„ç†ä»»ä½•æ–‡æœ¬æ•°æ®
            - ç»Ÿä¸€çš„æ¨¡å‹ç®¡ç†ç¡®ä¿é…ç½®ä¸€è‡´æ€§
            """)
        with col2:
            if st.button("ğŸ”§ å‰å¾€æ¨¡å‹ç®¡ç†", type="primary"):
                st.switch_page("ğŸ”¥ åµŒå…¥æ¨¡å‹ç®¡ç†")
                st.rerun()
        return

    # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
    st.markdown("### ğŸ”¥ å½“å‰æ¨¡å‹çŠ¶æ€")
    col1, col2 = st.columns([3, 1])
    vp = st.session_state["components"]["vector_processor"]
    with col1:
        st.success(f"âœ… å·²åŠ è½½æ¨¡å‹: **{current_model}**")
        model_info = vp.get_model_info()
        if model_info:
            st.info(f"ğŸ“Š å‘é‡ç»´åº¦: {model_info.get('dimension', 'N/A')}")
    with col2:
        if st.button("ğŸ”„ åˆ‡æ¢æ¨¡å‹"):
            st.info("ğŸ“Œ è¯·åˆ° 'ğŸ”¥ åµŒå…¥æ¨¡å‹ç®¡ç†' é¡µé¢åˆ‡æ¢æ¨¡å‹")

    st.markdown("---")

    # ===== æ•°æ®è´¨é‡è®¾ç½®ï¼ˆå¯æŠ˜å ï¼‰ =====
    with st.expander("âš™ï¸ æ•°æ®è´¨é‡è®¾ç½®ï¼ˆé«˜çº§ï¼‰", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            min_length = st.number_input(
                "æœ€å°æ–‡æœ¬é•¿åº¦",
                min_value=5,
                max_value=100,
                value=st.session_state.validator.min_length,
                help="çŸ­äºæ­¤é•¿åº¦çš„æ–‡æœ¬å°†è¢«è¿‡æ»¤"
            )
            max_url_count = st.number_input(
                "æœ€å¤§URLæ•°é‡",
                min_value=0,
                max_value=10,
                value=st.session_state.validator.max_url_count,
                help="åŒ…å«è¶…è¿‡æ­¤æ•°é‡URLçš„æ–‡æœ¬å°†è¢«è¿‡æ»¤"
            )
        
        with col2:
            min_chinese_ratio = st.slider(
                "æœ€å°ä¸­æ–‡æ¯”ä¾‹",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state.validator.min_chinese_ratio,
                step=0.05,
                format="%.2f",
                help="ä¸­æ–‡å­—ç¬¦å æ¯”ä½äºæ­¤å€¼çš„æ–‡æœ¬å°†è¢«è¿‡æ»¤"
            )
            max_special_ratio = st.slider(
                "æœ€å¤§ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state.validator.max_special_char_ratio,
                step=0.05,
                format="%.2f",
                help="ç‰¹æ®Šå­—ç¬¦å æ¯”é«˜äºæ­¤å€¼çš„æ–‡æœ¬å°†è¢«è¿‡æ»¤"
            )
        
        with col3:
            enable_strict = st.checkbox(
                "å¯ç”¨ä¸¥æ ¼æ¨¡å¼",
                value=st.session_state.validator.enable_strict_mode,
                help="å¯ç”¨æ›´ä¸¥æ ¼çš„è¿‡æ»¤è§„åˆ™"
            )
        
        if st.button("ğŸ’¾ åº”ç”¨è®¾ç½®"):
            st.session_state.validator = TextQualityValidator(
                min_length=min_length,
                max_url_count=max_url_count,
                min_chinese_ratio=min_chinese_ratio,
                max_special_char_ratio=max_special_ratio,
                enable_strict_mode=enable_strict
            )
            st.success("âœ… è®¾ç½®å·²æ›´æ–°")
            st.rerun()

    st.markdown("---")

    # æ•°æ®ä¸Šä¼ é€‰é¡¹
    upload_method = st.radio(
        "é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼",
        ["ğŸ“ ä¸Šä¼ JSONæ–‡ä»¶", "âœï¸ æ‰‹åŠ¨è¾“å…¥JSONæ•°æ®", "ğŸ“ ä½¿ç”¨ç¤ºä¾‹æ•°æ®"],
        horizontal=True
    )

    json_data = None
    validator = st.session_state.validator
    
    # ===== æ•°æ®è¾“å…¥éƒ¨åˆ† =====
    if upload_method == "ğŸ“ ä¸Šä¼ JSONæ–‡ä»¶":
        uploaded_file = st.file_uploader(
            "é€‰æ‹©JSONæ–‡ä»¶",
            type=['json', 'jsonl', 'txt'],
            help="æ”¯æŒJSONã€JSONLæ ¼å¼æ–‡ä»¶ã€‚JSONæ ¼å¼ï¼š[{\"text\":\"å†…å®¹\"}]ï¼ŒJSONLæ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡"
        )
        if uploaded_file is not None:
            try:
                file_content = uploaded_file.read().decode('utf-8')
                json_data = vp.parse_json_file(file_content)
                if not isinstance(json_data, list):
                    json_data = [json_data]
                
                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(json_data)} æ¡åŸå§‹æ•°æ®")
                file_size = uploaded_file.size / 1024 / 1024
                st.info(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                st.markdown("""
                **æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š**
                1. **æ ‡å‡†JSONæ•°ç»„**: `[{"text":"å†…å®¹1"}, {"text":"å†…å®¹2"}]`
                2. **JSONLæ ¼å¼**: æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
                3. **å•ä¸ªJSONå¯¹è±¡**: `{"text":"å†…å®¹"}`
                """)
                
    elif upload_method == "âœï¸ æ‰‹åŠ¨è¾“å…¥JSONæ•°æ®":
        json_text = st.text_area(
            "è¾“å…¥JSONæ•°æ®",
            height=200,
            placeholder='[{"text":"åŠç”Ÿé•¿ä»¥å®¢ä¸ºå®¶ï¼Œç½¢ç›´åˆæ¥ç€šæµ·æ§ã€‚å§‹ä¿¡äººé—´è¡Œä¸å°½ï¼Œå¤©æ¶¯æ›´å¤æœ‰å¤©æ¶¯ã€‚"}]',
            help="è¯·è¾“å…¥æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®"
        )
        if json_text.strip():
            try:
                json_data = vp.parse_json_file(json_text)
                if not isinstance(json_data, list):
                    json_data = [json_data]
                st.success(f"âœ… æˆåŠŸè§£æ {len(json_data)} æ¡åŸå§‹æ•°æ®")
            except Exception as e:
                st.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                
    elif upload_method == "ğŸ“ ä½¿ç”¨ç¤ºä¾‹æ•°æ®":
        sample_data = [
            {"text": "åŠç”Ÿé•¿ä»¥å®¢ä¸ºå®¶ï¼Œç½¢ç›´åˆæ¥ç€šæµ·æ§ã€‚å§‹ä¿¡äººé—´è¡Œä¸å°½ï¼Œå¤©æ¶¯æ›´å¤æœ‰å¤©æ¶¯ã€‚"},
            {"text": "æ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸€æ—¥çœ‹å°½é•¿å®‰èŠ±ã€‚"},
            {"text": "å±±é‡æ°´å¤ç–‘æ— è·¯ï¼ŒæŸ³æš—èŠ±æ˜åˆä¸€æ‘ã€‚"},
            {"text": "æµ·å†…å­˜çŸ¥å·±ï¼Œå¤©æ¶¯è‹¥æ¯”é‚»ã€‚"},
            {"text": "è½çº¢ä¸æ˜¯æ— æƒ…ç‰©ï¼ŒåŒ–ä½œæ˜¥æ³¥æ›´æŠ¤èŠ±ã€‚"},
            {"text": "ä¼šå½“å‡Œç»é¡¶ï¼Œä¸€è§ˆä¼—å±±å°ã€‚"},
            {"text": "é‡‡èŠä¸œç¯±ä¸‹ï¼Œæ‚ ç„¶è§å—å±±ã€‚"},
            {"text": "æ˜æœˆå‡ æ—¶æœ‰ï¼ŒæŠŠé…’é—®é’å¤©ã€‚"}
        ]
        json_data = sample_data
        st.info(f"ğŸ“ ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼Œå…± {len(json_data)} æ¡å¤è¯—è¯")

    # ===== æ•°æ®éªŒè¯å’Œé¢„è§ˆ =====
    if json_data:
        st.markdown("### ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")
        
        # éªŒè¯æ•°æ®
        with st.spinner("æ­£åœ¨éªŒè¯æ•°æ®è´¨é‡..."):
            valid_data, invalid_data, stats = batch_validate_and_clean(
                json_data, 
                validator,
                show_progress=True
            )
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“Š åŸå§‹æ•°æ®", len(json_data))
        with col2:
            st.metric("âœ… æœ‰æ•ˆæ•°æ®", len(valid_data), 
                     delta=f"{(len(valid_data)/len(json_data)*100):.1f}%")
        with col3:
            st.metric("âŒ æ— æ•ˆæ•°æ®", len(invalid_data))
        with col4:
            if valid_data:
                avg_quality = np.mean([d.get("_quality_score", 0) for d in valid_data])
                st.metric("â­ å¹³å‡è´¨é‡åˆ†", f"{avg_quality:.1f}")
        
        # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
        if stats:
            st.info(f"ğŸ“ˆ **éªŒè¯ç»Ÿè®¡**: {stats.get('é€šè¿‡ç‡', 'N/A')} é€šè¿‡ç‡")
            if invalid_data:
                with st.expander("âš ï¸ æŸ¥çœ‹æ‹’ç»åŸå› ç»Ÿè®¡"):
                    reasons = stats.get("ä¸»è¦æ‹’ç»åŸå› ", {})
                    for reason, count in reasons.items():
                        st.write(f"- **{reason}**: {count} æ¡")
        
        # æ˜¾ç¤ºæ— æ•ˆæ•°æ®æ ·ä¾‹
        if invalid_data:
            with st.expander(f"âŒ æŸ¥çœ‹æ— æ•ˆæ•°æ®æ ·ä¾‹ï¼ˆå…±{len(invalid_data)}æ¡ï¼‰"):
                sample_invalid = invalid_data[:5]
                for idx, item in enumerate(sample_invalid, 1):
                    st.markdown(f"**æ ·ä¾‹ {idx}**: {item['reason']}")
                    text_preview = str(item['item'].get('text', ''))[:100]
                    st.code(text_preview + "..." if len(text_preview) == 100 else text_preview)
                    st.markdown("---")
        
        # æ•°æ®é¢„è§ˆ
        if valid_data:
            st.markdown("### ğŸ“‹ æœ‰æ•ˆæ•°æ®é¢„è§ˆ")
            
            # è®¡ç®—ç»Ÿè®¡
            total_chars = sum(len(str(item.get('text', ''))) for item in valid_data)
            avg_length = total_chars / len(valid_data) if valid_data else 0
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ•°æ®æ¡æ•°", len(valid_data))
            with col2:
                st.metric("æ€»å­—ç¬¦æ•°", f"{total_chars:,}")
            with col3:
                st.metric("å¹³å‡é•¿åº¦", f"{avg_length:.1f}")
            
            # æ•°æ®è¡¨æ ¼é¢„è§ˆ
            df_preview = pd.DataFrame([
                {
                    "æ–‡æœ¬": item.get('text', '')[:50] + "..." if len(item.get('text', '')) > 50 else item.get('text', ''),
                    "è´¨é‡åˆ†": f"{item.get('_quality_score', 0):.1f}",
                    "é•¿åº¦": len(item.get('text', ''))
                }
                for item in valid_data[:10]
            ])
            st.dataframe(df_preview, use_container_width=True)
            
            if len(valid_data) > 10:
                st.info(f"æ˜¾ç¤ºå‰10æ¡æ•°æ®ï¼Œæ€»å…±{len(valid_data)}æ¡")
            
            # ===== å‘é‡åŒ–å¤„ç† =====
            st.markdown("### ğŸš€ å‘é‡åŒ–å¤„ç†")
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æ–‡æœ¬å‘é‡åŒ–å¤„ç†ï¼Œå¤„ç†åçš„æ•°æ®å¯ä»¥ä¿å­˜åˆ°Milvusæ•°æ®åº“ä¸­æ°¸ä¹…å­˜å‚¨")
            with col2:
                process_button = st.button("ğŸš€ å¼€å§‹å‘é‡åŒ–å¤„ç†å¹¶æŒä¹…åŒ–", type="primary")
            
            if process_button:
                progress_bar = st.progress(0)
                status_text = st.empty()
                try:
                    status_text.text("ğŸ”„ æ­£åœ¨å¤„ç†æ–‡æœ¬æ•°æ®...")
                    progress_bar.progress(30)
                    
                    # æå–æ–‡æœ¬ï¼ˆç§»é™¤è´¨é‡åˆ†æ•°å­—æ®µï¼‰
                    clean_data = [
                        {k: v for k, v in item.items() if k != "_quality_score"}
                        for item in valid_data
                    ]
                    
                    texts, vectors, metadata = vp.process_json_data(clean_data)
                    embedding_dim = vectors.shape[1]
                    progress_bar.progress(60)
                    
                    milvus_manager = st.session_state["components"]["milvus_manager"]
                    collection = milvus_manager.collection

                    # æ£€æŸ¥é›†åˆç»´åº¦é€»è¾‘è‡ªåŠ¨é‡å»º
                    need_rebuild = False
                    if collection:
                        milvus_dim = None
                        for f in collection.schema.fields:
                            if 'dim' in f.params:
                                milvus_dim = int(f.params['dim'])
                                break
                        if milvus_dim is None:
                            st.error("âŒ å½“å‰é›†åˆschemaæœªæ‰¾åˆ°å‘é‡ç»´åº¦(dim)å®šä¹‰ï¼Œè¯·æ£€æŸ¥é›†åˆå­—æ®µï¼")
                            progress_bar.empty()
                            status_text.empty()
                            return
                        if milvus_dim != embedding_dim:
                            status_text.text(
                                f"â— æ£€æµ‹åˆ°æ¨¡å‹å‘é‡ç»´åº¦({embedding_dim})ä¸Milvusé›†åˆ({milvus_dim})ä¸ä¸€è‡´ï¼Œè‡ªåŠ¨é‡å»ºé›†åˆ..."
                            )
                            milvus_manager.delete_collection()
                            need_rebuild = True
                    else:
                        need_rebuild = True

                    if need_rebuild:
                        success = milvus_manager.create_collection(embedding_dim)
                        if not success:
                            st.error("âŒ Milvusé›†åˆé‡å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œé…ç½®ä¿¡æ¯ï¼")
                            progress_bar.empty()
                            status_text.empty()
                            return
                        status_text.text(f"âœ… Milvusé›†åˆå·²é‡å»ºï¼Œç»´åº¦: {embedding_dim}")
                        progress_bar.progress(80)
                        milvus_manager.get_collection_object()

                    # æ•°æ®å·²ç»è¿‡æ¸…æ´—ï¼Œç›´æ¥å¤„ç†
                    texts_clean = [t[0] if isinstance(t, list) and len(t) > 0 else t for t in texts]
                    texts_clean = [str(t) for t in texts_clean]

                    # å­˜å‚¨åˆ°session state
                    st.session_state.texts = texts_clean
                    st.session_state.vectors = vectors
                    st.session_state.metadata = metadata
                    st.session_state.data_loaded = True
                    
                    try:
                        inserted_ids = milvus_mongo_upload(
                            texts_clean, vectors, metadata, milvus_dim=embedding_dim
                        )
                        progress_bar.progress(100)
                        status_text.text(f"âœ… å‘é‡åŒ–åŠæŒä¹…åŒ–å®Œæˆï¼å·²æ’å…¥ {len(inserted_ids)} æ¡æ•°æ®ã€‚")
                        st.success(f"ğŸ‰ å‘é‡åŒ–å’ŒæŒä¹…åŒ–å®Œæˆï¼æˆåŠŸå¤„ç†å¹¶å†™å…¥ {len(inserted_ids)} æ¡æ–‡æœ¬æ•°æ®ã€‚")
                    except Exception as e:
                        progress_bar.progress(100)
                        status_text.text("âš ï¸ å‘é‡åŒ–å®Œæˆï¼Œä½†æŒä¹…åŒ–å¤±è´¥")
                        st.warning(f"âš ï¸ å‘é‡åŒ–å®Œæˆï¼Œä½†æ•°æ®æŒä¹…åŒ–å¤±è´¥: {e}")
                        st.info("ğŸ’¡ æ•°æ®å·²ä¿å­˜åˆ°å†…å­˜ä¸­ï¼Œå¯ä»¥è¿›è¡Œæœç´¢å’Œèšç±»åˆ†æã€‚è¦å¯ç”¨æŒä¹…åŒ–ï¼Œè¯·æ£€æŸ¥Milvuså’ŒMongoDBè¿æ¥ã€‚")

                    # æœç´¢å¼•æ“ã€èšç±»åˆ†æåŒæ­¥
                    st.session_state.components['search_engine'].load_data(vectors, texts_clean, metadata)
                    st.session_state.components['search_engine'].set_vector_processor(vp)
                    st.session_state.components['clustering_analyzer'].load_data(vectors, texts_clean, metadata)
                    st.success(f"âœ… å‘é‡åŒ–å®Œæˆï¼æˆåŠŸå¤„ç†äº† {len(texts_clean)} æ¡æ–‡æœ¬")
                    
                except Exception as e:
                    st.error(f"âŒ å‘é‡åŒ–å¤„ç†å¤±è´¥: {e}")
                    st.exception(e)
                finally:
                    progress_bar.empty()
                    status_text.empty()
        else:
            st.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ä»¥å¤„ç†ï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡è®¾ç½®æˆ–æ•°æ®å†…å®¹")


# ============================================
# è¾…åŠ©å‡½æ•°ï¼šæ˜¾ç¤ºéªŒè¯å™¨çŠ¶æ€
# ============================================

def show_validator_status():
    """åœ¨ä¾§è¾¹æ æ˜¾ç¤ºéªŒè¯å™¨çŠ¶æ€"""
    if "validator" in st.session_state:
        validator = st.session_state.validator
        with st.sidebar:
            st.markdown("### ğŸ” å½“å‰è´¨é‡è®¾ç½®")
            st.markdown(f"- **æœ€å°é•¿åº¦**: {validator.min_length}")
            st.markdown(f"- **æœ€å¤§URLæ•°**: {validator.max_url_count}")
            st.markdown(f"- **æœ€å°ä¸­æ–‡æ¯”ä¾‹**: {validator.min_chinese_ratio:.1%}")
            st.markdown(f"- **ä¸¥æ ¼æ¨¡å¼**: {'âœ… å¼€å¯' if validator.enable_strict_mode else 'âŒ å…³é—­'}")
            
            if validator.stats["total"] > 0:
                st.markdown("---")
                st.markdown("### ğŸ“Š æœ¬æ¬¡ç»Ÿè®¡")
                st.markdown(f"- **æ€»éªŒè¯**: {validator.stats['total']}")
                st.markdown(f"- **é€šè¿‡**: {validator.stats['accepted']}")
                st.markdown(f"- **æ‹’ç»**: {validator.stats['rejected']}")


