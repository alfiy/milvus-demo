import numpy as np
import streamlit as st
from sentence_transformers import SentenceTransformer
import os
from typing import List, Dict, Any
import torch
import json

class VectorProcessor:
    def __init__(self):
        """
        åˆå§‹åŒ–å‘é‡å¤„ç†å™¨ï¼Œä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹
        """
        self.model = None
        self.model_name = "paraphrase-multilingual-MiniLM-L12-v2"
        self.dimension = 384  # è¯¥æ¨¡å‹çš„å‘é‡ç»´åº¦
        
        # è®¾ç½®æœ¬åœ°ç¼“å­˜è·¯å¾„
        self.cache_dir = os.path.expanduser("~/.cache/huggingface/transformers")


    def load_model(self) -> bool:
        """
        åŠ è½½é¢„è®­ç»ƒçš„å¥å­è½¬æ¢æ¨¡å‹ï¼Œè‡ªåŠ¨ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€æ‰‹åŠ¨æ£€æµ‹ç¼“å­˜
        """
        try:
            st.info("ï”„ æ­£åœ¨åŠ è½½æ–‡æœ¬å‘é‡åŒ–æ¨¡å‹...")
            device = "cuda" if torch.cuda.is_available() else "cpu"
            st.info(f"ï–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")

            # ç›´æ¥åŠ è½½æ¨¡å‹ï¼ŒHuggingfaceä¼šè‡ªåŠ¨ä½¿ç”¨ç¼“å­˜
            self.model = SentenceTransformer(
                self.model_name,
                cache_folder=self.cache_dir,
                device=device
            )
            st.success("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

            # éªŒè¯æ¨¡å‹
            test_text = "æµ‹è¯•æ–‡æœ¬"
            test_vector = self.model.encode([test_text])
            if test_vector.shape[1] == self.dimension:
                st.success(f"ğŸ“Š æ¨¡å‹ç»´åº¦: {self.dimension} | æè¿°: æ”¯æŒå¤šè¯­è¨€ï¼Œ384ç»´å‘é‡ï¼Œå¹³è¡¡æ€§èƒ½ä¸è´¨é‡")
                return True
            else:
                st.error(f"âŒ æ¨¡å‹ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.dimension}ï¼Œå®é™…{test_vector.shape[1]}")
                return False

        except Exception as e:
            st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # å°è¯•å¤‡ç”¨æ¨¡å‹
            st.info("ï’¡ å°è¯•ä½¿ç”¨å¤‡ç”¨æ¨¡å‹...")
            try:
                backup_model = "all-MiniLM-L6-v2"
                self.model = SentenceTransformer(backup_model, device=device)
                self.dimension = 384
                st.warning(f"âš ï¸ ä½¿ç”¨å¤‡ç”¨æ¨¡å‹: {backup_model}")
                return True
            except Exception as backup_e:
                st.error(f"âŒ å¤‡ç”¨æ¨¡å‹åŠ è½½å¤±è´¥: {backup_e}")
                return False

    
    def preprocess_text(self, text: str) -> str:
        """
        æ–‡æœ¬é¢„å¤„ç†
        """
        if not text:
            return ""
        
        # åŸºæœ¬æ¸…ç†
        text = text.strip()
        # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šé¢„å¤„ç†æ­¥éª¤
        return text
    
    def parse_json_file(self, file_content: str) -> List[Dict[str, Any]]:
        """
        è§£æJSONæ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        """
        json_data = []
        
        try:
            # å°è¯•ç›´æ¥è§£æä¸ºJSON
            data = json.loads(file_content)
            if isinstance(data, list):
                json_data = data
            elif isinstance(data, dict):
                json_data = [data]
            else:
                st.error("JSONæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸ºå¯¹è±¡æˆ–å¯¹è±¡æ•°ç»„")
                return []
        except json.JSONDecodeError as e:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æŒ‰è¡Œè§£æï¼ˆJSONLæ ¼å¼ï¼‰
            st.info("å°è¯•æŒ‰JSONLæ ¼å¼è§£æ...")
            lines = file_content.strip().split('\n')
            
            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue
                    
                try:
                    item = json.loads(line)
                    json_data.append(item)
                except json.JSONDecodeError as line_error:
                    st.warning(f"ç¬¬{i+1}è¡ŒJSONè§£æå¤±è´¥: {line_error}")
                    st.warning(f"é—®é¢˜è¡Œå†…å®¹: {line[:100]}...")
                    continue
            
            if not json_data:
                st.error(f"æ— æ³•è§£æJSONæ–‡ä»¶ã€‚åŸå§‹é”™è¯¯: {e}")
                st.error("è¯·ç¡®ä¿æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¾‹å¦‚ï¼š")
                st.code('[{"text":"æ–‡æœ¬å†…å®¹1"}, {"text":"æ–‡æœ¬å†…å®¹2"}]')
                st.error("æˆ–è€…JSONLæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰ï¼š")
                st.code('{"text":"æ–‡æœ¬å†…å®¹1"}\n{"text":"æ–‡æœ¬å†…å®¹2"}')
                return []
        
        return json_data
    
    def process_json_data(self, json_data: List[Dict[str, Any]]) -> tuple:
        """
        å¤„ç†JSONæ ¼å¼çš„æ•°æ®
        è¿”å›æ–‡æœ¬åˆ—è¡¨å’Œå¯¹åº”çš„å‘é‡
        """
        texts = []
        metadata = []
        
        for i, item in enumerate(json_data):
            if isinstance(item, dict):
                for key, value in item.items():
                    if isinstance(value, str) and value.strip():
                        texts.append(value)
                        metadata.append({
                            'id': i,
                            'key': key,
                            'original_data': item
                        })
            elif isinstance(item, str) and item.strip():
                # å¦‚æœç›´æ¥æ˜¯å­—ç¬¦ä¸²
                texts.append(item)
                metadata.append({
                    'id': i,
                    'key': 'text',
                    'original_data': {'text': item}
                })
        
        if not texts:
            return [], [], []
        
        # ç¼–ç æ–‡æœ¬
        vectors = self.encode_texts(texts)
        
        return texts, vectors, metadata
    
    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """
        å°†æ–‡æœ¬åˆ—è¡¨ç¼–ç ä¸ºå‘é‡
        """
        if not self.model:
            st.error("âŒ æ¨¡å‹æœªåŠ è½½")
            return np.array([])
        
        try:
            st.info(f"ğŸ”„ æ­£åœ¨å¤„ç† {len(texts)} æ¡æ–‡æœ¬...")
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            all_vectors = []
            total_batches = (len(texts) + batch_size - 1) // batch_size
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                
                # é¢„å¤„ç†æ–‡æœ¬
                processed_texts = [self.preprocess_text(text) for text in batch_texts]
                
                # ç¼–ç å½“å‰æ‰¹æ¬¡
                batch_vectors = self.model.encode(
                    processed_texts,
                    convert_to_numpy=True,
                    show_progress_bar=False,
                    batch_size=min(batch_size, len(batch_texts))
                )
                
                all_vectors.append(batch_vectors)
                
                # æ›´æ–°è¿›åº¦
                current_batch = (i // batch_size) + 1
                progress = current_batch / total_batches
                progress_bar.progress(progress)
                status_text.text(f"âœ… å·²å¤„ç† {min(i + batch_size, len(texts))}/{len(texts)} æ¡æ–‡æœ¬")
            
            # åˆå¹¶æ‰€æœ‰å‘é‡
            vectors = np.vstack(all_vectors)
            
            progress_bar.progress(1.0)
            status_text.text(f"ğŸ‰ æ–‡æœ¬å‘é‡åŒ–å®Œæˆï¼ç”Ÿæˆ {vectors.shape[0]} ä¸ª {vectors.shape[1]} ç»´å‘é‡")
            
            return vectors
            
        except Exception as e:
            st.error(f"âŒ æ–‡æœ¬ç¼–ç å¤±è´¥: {e}")
            return np.array([])
        finally:
            # æ¸…ç†è¿›åº¦æ˜¾ç¤º
            if 'progress_bar' in locals():
                progress_bar.empty()
            if 'status_text' in locals():
                status_text.empty()
    
    def encode_single_text(self, text: str) -> np.ndarray:
        """
        ç¼–ç å•ä¸ªæ–‡æœ¬ä¸ºå‘é‡
        """
        if not self.model:
            st.error("âŒ æ¨¡å‹æœªåŠ è½½")
            return np.array([])
        
        try:
            processed_text = self.preprocess_text(text)
            vector = self.model.encode([processed_text], convert_to_numpy=True)
            return vector[0]  # è¿”å›å•ä¸ªå‘é‡
        except Exception as e:
            st.error(f"âŒ å•æ–‡æœ¬ç¼–ç å¤±è´¥: {e}")
            return np.array([])
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        """
        if not self.model:
            return {}
        
        return {
            'model_name': self.model_name,
            'dimension': self.dimension,
            'device': str(self.model.device),
            'max_seq_length': getattr(self.model, 'max_seq_length', 'Unknown'),
            'cache_dir': self.cache_dir,
            'embedding_dimension': self.model.get_sentence_embedding_dimension()
        }
    
    def calculate_similarity(self, vector1: np.ndarray, vector2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        """
        try:
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            dot_product = np.dot(vector1, vector2)
            norm1 = np.linalg.norm(vector1)
            norm2 = np.linalg.norm(vector2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            similarity = dot_product / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            st.error(f"âŒ ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    

