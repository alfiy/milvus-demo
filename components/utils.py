from pymongo import MongoClient
import numpy as np
import streamlit as st
import logging
from typing import List, Dict, Any, Optional, Tuple
import time
from dataclasses import dataclass
from sklearn.preprocessing import normalize

# ============================================================
# æ•°æ®ç±»å’Œå¼‚å¸¸ç±»
# ============================================================

@dataclass
class SearchResult:
    """æœç´¢ç»“æœæ•°æ®ç±»"""
    id: str
    score: float
    text: str
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "score": self.score,
            "text": self.text,
            "metadata": self.metadata
        }


class VectorSearchError(Exception):
    """å‘é‡æœç´¢å¼‚å¸¸åŸºç±»"""
    pass


class VectorEncodingError(VectorSearchError):
    """å‘é‡ç¼–ç å¼‚å¸¸"""
    pass


class MilvusSearchError(VectorSearchError):
    """Milvusæœç´¢å¼‚å¸¸"""
    pass


class MongoQueryError(VectorSearchError):
    """MongoDBæŸ¥è¯¢å¼‚å¸¸"""
    pass


# ============================================================
# ä¸»æœç´¢å‡½æ•°
# ============================================================

def vector_search(
    query: str,
    top_k: int,
    milvus_collection,
    mongo_col,
    vector_processor,
    filter_mode: str = "similarity",
    filter_threshold: float = 0.0,
    output_fields: List[str] = None,
    nprobe: int = 10,
    timeout: float = 30.0,
    enable_stats: bool = False,
    metric_type: str = "COSINE"  # ğŸ¯ æ–°å¢ï¼šæ”¯æŒé…ç½®æŒ‡æ ‡ç±»å‹
) -> List[Dict[str, Any]]:
    """
    ä¼˜åŒ–åçš„å‘é‡+Mongoæ··åˆæœç´¢åŠŸèƒ½
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        top_k: è¿”å›top-kç»“æœ
        milvus_collection: Milvusé›†åˆå¯¹è±¡
        mongo_col: MongoDBé›†åˆå¯¹è±¡
        vector_processor: å‘é‡åŒ–å¤„ç†å™¨
        filter_mode: è¿‡æ»¤æ¨¡å¼ï¼Œ"similarity"(ç›¸ä¼¼åº¦ï¼Œè¶Šå¤§è¶Šå¥½) æˆ– "distance"(è·ç¦»ï¼Œè¶Šå°è¶Šå¥½)
        filter_threshold: è¿‡æ»¤é˜ˆå€¼
        output_fields: ä»MongoDBè·å–çš„å­—æ®µåˆ—è¡¨
        nprobe: Milvusæœç´¢çš„nprobeå‚æ•°
        timeout: æœç´¢è¶…æ—¶æ—¶é—´(ç§’)
        enable_stats: æ˜¯å¦è¿”å›ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¼šæ·»åŠ åˆ°ç¬¬ä¸€ä¸ªç»“æœçš„metadataä¸­ï¼‰
        metric_type: è·ç¦»åº¦é‡ç±»å‹ï¼Œé»˜è®¤"COSINE"
        
    Returns:
        ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœåŒ…å«: id, score, text, metadata
        å¦‚æœenable_stats=Trueï¼Œä¼šåœ¨ç¬¬ä¸€ä¸ªç»“æœçš„metadataä¸­æ·»åŠ '_search_stats'å­—æ®µ
        
    Raises:
        VectorSearchError: æœç´¢è¿‡ç¨‹ä¸­çš„å„ç±»å¼‚å¸¸
    """
    stats = {"start_time": time.time()} if enable_stats else None
    
    # å‚æ•°éªŒè¯
    _validate_params(query, top_k, filter_mode, filter_threshold, output_fields)
    
    if output_fields is None:
        output_fields = ["text", "metadata"]
    
    try:
        # 1. å‘é‡åŒ–æŸ¥è¯¢
        query_vector = _encode_query(query, vector_processor, stats)
        
        # 2. Milvuså‘é‡æœç´¢
        milvus_results = _search_milvus(
            query_vector=query_vector,
            milvus_collection=milvus_collection,
            top_k=top_k,
            output_fields=output_fields,
            nprobe=nprobe,
            timeout=timeout,
            stats=stats,
            metric_type=metric_type  # ğŸ¯ ä¼ é€’metric_type
        )
        
        if not milvus_results:
            logging.warning("Milvusè¿”å›ç©ºç»“æœ")
            return []
        
        # 3. æ‰¹é‡æŸ¥è¯¢MongoDBå…ƒæ•°æ®
        enriched_results = _enrich_with_mongo(
            milvus_results=milvus_results,
            mongo_col=mongo_col,
            output_fields=output_fields,
            timeout=timeout,
            stats=stats
        )
        
        # 4. åº”ç”¨è¿‡æ»¤
        filtered_results = _apply_filter(
            results=enriched_results,
            filter_mode=filter_mode,
            filter_threshold=filter_threshold,
            stats=stats
        )
        
        if enable_stats and filtered_results:
            stats["total_time"] = time.time() - stats["start_time"]
            stats["final_count"] = len(filtered_results)
            # å°†ç»Ÿè®¡ä¿¡æ¯æ·»åŠ åˆ°ç¬¬ä¸€ä¸ªç»“æœçš„metadataä¸­
            filtered_results[0]["_search_stats"] = stats
        
        return filtered_results
        
    except VectorSearchError:
        raise
    except Exception as e:
        logging.error(f"å‘é‡æ£€ç´¢æœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        raise VectorSearchError(f"æœç´¢å¤±è´¥: {str(e)}") from e


# ============================================================
# è¾…åŠ©å‡½æ•°
# ============================================================

def _validate_params(
    query: str,
    top_k: int,
    filter_mode: str,
    filter_threshold: float,
    output_fields: Optional[List[str]]
) -> None:
    """éªŒè¯è¾“å…¥å‚æ•°"""
    if not query or not query.strip():
        raise ValueError("æŸ¥è¯¢æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    if top_k <= 0:
        raise ValueError(f"top_kå¿…é¡»å¤§äº0ï¼Œå½“å‰å€¼: {top_k}")
    
    if top_k > 1000:
        logging.warning(f"top_k={top_k}è¿‡å¤§ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
    
    if filter_mode not in ["similarity", "distance"]:
        raise ValueError(f"filter_modeå¿…é¡»æ˜¯'similarity'æˆ–'distance'ï¼Œå½“å‰å€¼: {filter_mode}")
    
    if not 0 <= filter_threshold <= 1:
        logging.warning(f"filter_threshold={filter_threshold}å¯èƒ½è¶…å‡ºå¸¸è§„èŒƒå›´[0, 1]")
    
    if output_fields and not isinstance(output_fields, list):
        raise ValueError("output_fieldså¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹")


def _encode_query(query: str, vector_processor, stats: Optional[Dict]) -> List[float]:
    """å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬"""
    try:
        if stats is not None:
            encode_start = time.time()
        
        query_vector = vector_processor.encode([query])[0]
        
        # å‘é‡å½’ä¸€åŒ–ï¼ˆå¯é€‰ï¼Œæ ¹æ®å®é™…éœ€æ±‚å†³å®šæ˜¯å¦ä½¿ç”¨ï¼‰
        # æ³¨æ„ï¼šå¦‚æœè®­ç»ƒæ•°æ®æ²¡æœ‰å½’ä¸€åŒ–ï¼Œè¿™é‡Œä¹Ÿä¸åº”è¯¥å½’ä¸€åŒ–
        query_vector = normalize([query_vector], axis=1)[0]
        
        if stats is not None:
            stats["encode_time"] = time.time() - encode_start
            stats["vector_dim"] = len(query_vector)
        
        return query_vector.tolist() if hasattr(query_vector, 'tolist') else list(query_vector)
        
    except Exception as e:
        logging.error(f"å‘é‡ç¼–ç å¤±è´¥: {e}")
        raise VectorEncodingError(f"æ— æ³•ç¼–ç æŸ¥è¯¢æ–‡æœ¬: {str(e)}") from e


def _search_milvus(
    query_vector: List[float],
    milvus_collection,
    top_k: int,
    output_fields: List[str],
    nprobe: int,
    timeout: float,
    stats: Optional[Dict],
    metric_type: str = "COSINE"  # ğŸ¯ æ–°å¢å‚æ•°
) -> List[Tuple[str, float]]:
    """
    æ‰§è¡ŒMilvuså‘é‡æœç´¢
    
    Returns:
        List[Tuple[str, float]]: (æ–‡æ¡£ID, åˆ†æ•°) åˆ—è¡¨
        - COSINE: è¿”å›ç›¸ä¼¼åº¦ [0, 1]ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸åŒ
        - L2: è¿”å›è·ç¦»ï¼Œè¶Šå°è¶Šç›¸ä¼¼
        - IP: è¿”å›å†…ç§¯ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼
    """
    try:
        if stats is not None:
            milvus_start = time.time()
        
        # ğŸ¯ ä¼˜åŒ–1ï¼šè¾“å…¥éªŒè¯
        if not query_vector:
            raise ValueError("æŸ¥è¯¢å‘é‡ä¸èƒ½ä¸ºç©º")
        
        if top_k <= 0:
            raise ValueError(f"top_kå¿…é¡»å¤§äº0ï¼Œå½“å‰å€¼: {top_k}")
        
        # ğŸ¯ ä¼˜åŒ–2ï¼šä½¿ç”¨ä¼ å…¥çš„metric_type
        search_params = {
            "metric_type": metric_type,
            "params": {"nprobe": nprobe}
        }
        
        # ğŸ¯ ä¼˜åŒ–3ï¼šè®°å½•æœç´¢å‚æ•°ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        if stats is not None:
            stats["search_params"] = {
                "metric_type": metric_type,
                "nprobe": nprobe,
                "top_k": top_k,
                "vector_dim": len(query_vector)
            }
        
        results = milvus_collection.search(
            data=[query_vector],
            anns_field="vector",
            param=search_params,
            limit=top_k,
            output_fields=[],  # åªè·å–IDå’Œåˆ†æ•°ï¼Œå…ƒæ•°æ®ä»MongoDBè·å–
            timeout=timeout
        )
        
        # ğŸ¯ ä¼˜åŒ–4ï¼šæ›´è¯¦ç»†çš„ç©ºç»“æœæ£€æŸ¥
        if not results:
            logging.warning("Milvusè¿”å›ç©ºç»“æœå¯¹è±¡")
            return []
        
        if not results[0]:
            logging.warning("Milvusè¿”å›ç©ºæœç´¢ç»“æœåˆ—è¡¨")
            return []
        
        # ğŸ¯ ä¼˜åŒ–5ï¼šæ ¹æ®æŒ‡æ ‡ç±»å‹æ™ºèƒ½è½¬æ¢åˆ†æ•°
        milvus_results = _convert_scores(
            hits=results[0],
            metric_type=metric_type,
            stats=stats
        )
        
        # ğŸ¯ ä¼˜åŒ–6ï¼šè®°å½•æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
        if stats is not None:
            stats["milvus_time"] = time.time() - milvus_start
            stats["milvus_count"] = len(milvus_results)
            stats["milvus_metric"] = metric_type
            
            # è®°å½•åˆ†æ•°ç»Ÿè®¡
            if milvus_results:
                scores = [score for _, score in milvus_results]
                stats["score_stats"] = {
                    "min": min(scores),
                    "max": max(scores),
                    "avg": sum(scores) / len(scores)
                }
        
        # ğŸ¯ ä¼˜åŒ–7ï¼šè®°å½•æœç´¢è´¨é‡è­¦å‘Š
        if milvus_results:
            _log_search_quality_warnings(milvus_results, metric_type, top_k)
        
        return milvus_results
        
    except ValueError as e:
        # å‚æ•°é”™è¯¯
        logging.error(f"Milvusæœç´¢å‚æ•°é”™è¯¯: {e}")
        raise MilvusSearchError(f"æœç´¢å‚æ•°æ— æ•ˆ: {str(e)}") from e
        
    except Exception as e:
        # å…¶ä»–é”™è¯¯
        logging.error(f"Milvusæœç´¢å¤±è´¥: {e}", exc_info=True)
        raise MilvusSearchError(f"å‘é‡æœç´¢å¤±è´¥: {str(e)}") from e


def _convert_scores(
    hits,
    metric_type: str,
    stats: Optional[Dict] = None
) -> List[Tuple[str, float]]:
    """
    æ ¹æ®åº¦é‡ç±»å‹è½¬æ¢æœç´¢ç»“æœçš„åˆ†æ•°
    
    Args:
        hits: Milvusæœç´¢ç»“æœçš„hitå¯¹è±¡åˆ—è¡¨
        metric_type: åº¦é‡ç±»å‹
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        (ID, è½¬æ¢åçš„åˆ†æ•°) å…ƒç»„åˆ—è¡¨
        
    Note:
        ä¸åŒåº¦é‡ç±»å‹çš„è½¬æ¢è§„åˆ™ï¼š
        - COSINE: è½¬æ¢ä¸ºç›¸ä¼¼åº¦ (1 - distance)ï¼ŒèŒƒå›´ [0, 1]ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼
        - L2: ä¿æŒè·ç¦»å€¼ï¼ŒèŒƒå›´ [0, âˆ)ï¼Œè¶Šå°è¶Šç›¸ä¼¼
        - IP: ä¿æŒå†…ç§¯å€¼ï¼ŒèŒƒå›´ (-âˆ, âˆ)ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼
    """
    results = []
    raw_distances = []
    
    for hit in hits:
        hit_id = str(hit.id)  # ç»Ÿä¸€è½¬ä¸ºå­—ç¬¦ä¸²ID
        raw_distance = float(hit.distance)
        raw_distances.append(raw_distance)
        
        # æ ¹æ®æŒ‡æ ‡ç±»å‹è½¬æ¢åˆ†æ•°
        if metric_type == "COSINE":
            # COSINE: å°†è·ç¦»è½¬ä¸ºç›¸ä¼¼åº¦
            score = 1.0 - raw_distance
            # å¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜ï¼Œç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
            score = max(0.0, min(1.0, score))
        elif metric_type == "L2":
            # L2: ä¿æŒè·ç¦»å€¼ï¼Œè¶Šå°è¶Šç›¸ä¼¼
            score = raw_distance
        elif metric_type == "IP":
            # IP (å†…ç§¯): ä¿æŒåŸå€¼ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼
            score = raw_distance
        else:
            # å…¶ä»–æœªçŸ¥æŒ‡æ ‡ï¼šä¿æŒåŸå€¼å¹¶è®°å½•è­¦å‘Š
            logging.warning(f"æœªçŸ¥çš„åº¦é‡ç±»å‹: {metric_type}ï¼Œä½¿ç”¨åŸå§‹è·ç¦»å€¼")
            score = raw_distance
        
        results.append((hit_id, score))
    
    # è®°å½•åŸå§‹è·ç¦»ç»Ÿè®¡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    if stats is not None and raw_distances:
        stats["raw_distance_stats"] = {
            "min": min(raw_distances),
            "max": max(raw_distances),
            "avg": sum(raw_distances) / len(raw_distances)
        }
    
    return results


def _log_search_quality_warnings(
    results: List[Tuple[str, float]],
    metric_type: str,
    top_k: int
) -> None:
    """
    è®°å½•æœç´¢è´¨é‡ç›¸å…³çš„è­¦å‘Šä¿¡æ¯
    
    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨
        metric_type: åº¦é‡ç±»å‹
        top_k: è¯·æ±‚çš„ç»“æœæ•°é‡
    """
    if not results:
        return
    
    scores = [score for _, score in results]
    
    # è­¦å‘Š1ï¼šè¿”å›ç»“æœå°‘äºè¯·æ±‚æ•°é‡
    if len(results) < top_k:
        logging.warning(
            f"è¿”å›ç»“æœæ•°({len(results)})å°‘äºè¯·æ±‚æ•°({top_k})ï¼Œ"
            f"å¯èƒ½æ˜¯é›†åˆä¸­æ•°æ®ä¸è¶³"
        )
    
    # è­¦å‘Š2ï¼šCOSINEç›¸ä¼¼åº¦éƒ½å¾ˆä½
    if metric_type == "COSINE":
        max_score = max(scores)
        avg_score = sum(scores) / len(scores)
        
        if max_score < 0.3:
            logging.warning(
                f"æœ€é«˜ç›¸ä¼¼åº¦ä»…ä¸º{max_score:.3f}ï¼Œå»ºè®®æ£€æŸ¥ï¼š"
                "1) æŸ¥è¯¢æ–‡æœ¬æ˜¯å¦åˆé€‚ "
                "2) å‘é‡æ¨¡å‹æ˜¯å¦åŒ¹é… "
                "3) æ•°æ®åº“ä¸­æ˜¯å¦æœ‰ç›¸å…³å†…å®¹"
            )
        elif avg_score < 0.2:
            logging.warning(
                f"å¹³å‡ç›¸ä¼¼åº¦ä»…ä¸º{avg_score:.3f}ï¼Œå¤§éƒ¨åˆ†ç»“æœå¯èƒ½ä¸ç›¸å…³"
            )
    
    # è­¦å‘Š3ï¼šL2è·ç¦»éƒ½å¾ˆå¤§
    elif metric_type == "L2":
        min_distance = min(scores)
        
        if min_distance > 100:  # é˜ˆå€¼å¯è°ƒæ•´
            logging.warning(
                f"æœ€å°L2è·ç¦»ä¸º{min_distance:.2f}ï¼Œæ‰€æœ‰ç»“æœå¯èƒ½éƒ½ä¸ç›¸å…³"
            )
    
    # è­¦å‘Š4ï¼šåˆ†æ•°åˆ†å¸ƒå¼‚å¸¸
    score_range = max(scores) - min(scores)
    if metric_type == "COSINE" and score_range < 0.01:
        logging.warning(
            f"ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´å¾ˆå°({score_range:.4f})ï¼Œ"
            "å¯èƒ½è¡¨ç¤ºæŸ¥è¯¢å‘é‡è´¨é‡é—®é¢˜æˆ–æ•°æ®åŒè´¨åŒ–ä¸¥é‡"
        )


def _enrich_with_mongo(
    milvus_results: List[Tuple[str, float]],
    mongo_col,
    output_fields: List[str],
    timeout: float,
    stats: Optional[Dict]
) -> List[SearchResult]:
    """ç”¨MongoDBæ•°æ®ä¸°å¯Œæœç´¢ç»“æœ"""
    try:
        if stats is not None:
            mongo_start = time.time()
        
        # æå–æ‰€æœ‰ID
        ids = [id_ for id_, _ in milvus_results]
        
        if not ids:
            return []
        
        # æ‰¹é‡æŸ¥è¯¢MongoDB - æ³¨æ„IDç±»å‹è½¬æ¢
        projection = {field: 1 for field in output_fields}
        projection["_id"] = 1
        
        docs = []
        id_mappings = {}  # è®°å½•IDæ˜ å°„å…³ç³»ï¼šMongoDB _id -> Milvus id
        
        # ç­–ç•¥1: ç›´æ¥ç”¨å­—ç¬¦ä¸²IDæŸ¥è¯¢
        logging.debug(f"å°è¯•å­—ç¬¦ä¸²IDæŸ¥è¯¢: {ids[:3]}...")
        docs = list(mongo_col.find(
            {"_id": {"$in": ids}},
            projection
        ).max_time_ms(int(timeout * 1000)))
        
        if docs:
            logging.info(f"å­—ç¬¦ä¸²IDæŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ° {len(docs)} æ¡è®°å½•")
            for doc in docs:
                id_mappings[str(doc["_id"])] = str(doc["_id"])
        
        # ç­–ç•¥2: å°è¯•è½¬æ¢ä¸ºObjectId
        if len(docs) < len(ids):
            try:
                from bson import ObjectId
                logging.debug("å°è¯•ObjectIdè½¬æ¢...")
                
                # æ”¶é›†æœªæ‰¾åˆ°çš„ID
                found_ids = {str(doc["_id"]) for doc in docs}
                missing_ids = [id_ for id_ in ids if id_ not in found_ids]
                
                # å°è¯•è½¬æ¢ä¸ºObjectId
                object_ids = []
                oid_to_str = {}  # ObjectId -> åŸå§‹å­—ç¬¦ä¸²æ˜ å°„
                
                for id_str in missing_ids:
                    if ObjectId.is_valid(id_str):
                        oid = ObjectId(id_str)
                        object_ids.append(oid)
                        oid_to_str[oid] = id_str
                
                if object_ids:
                    oid_docs = list(mongo_col.find(
                        {"_id": {"$in": object_ids}},
                        projection
                    ).max_time_ms(int(timeout * 1000)))
                    
                    if oid_docs:
                        logging.info(f"ObjectIdæŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ° {len(oid_docs)} æ¡è®°å½•")
                        for doc in oid_docs:
                            # å»ºç«‹æ˜ å°„ï¼šåŸå§‹Milvuså­—ç¬¦ä¸²ID -> MongoDBæ–‡æ¡£
                            original_str = oid_to_str.get(doc["_id"])
                            if original_str:
                                id_mappings[original_str] = str(doc["_id"])
                        docs.extend(oid_docs)
                        
            except Exception as oid_error:
                logging.warning(f"ObjectIdè½¬æ¢å¤±è´¥: {oid_error}")
        
        # ç­–ç•¥3: å°è¯•è½¬æ¢ä¸ºæ•´æ•°ID
        if len(docs) < len(ids):
            try:
                logging.debug("å°è¯•æ•´æ•°IDè½¬æ¢...")
                found_ids = set(id_mappings.keys())
                missing_ids = [id_ for id_ in ids if id_ not in found_ids]
                
                int_ids = []
                int_to_str = {}
                
                for id_str in missing_ids:
                    try:
                        int_id = int(id_str)
                        int_ids.append(int_id)
                        int_to_str[int_id] = id_str
                    except ValueError:
                        continue
                
                if int_ids:
                    int_docs = list(mongo_col.find(
                        {"_id": {"$in": int_ids}},
                        projection
                    ).max_time_ms(int(timeout * 1000)))
                    
                    if int_docs:
                        logging.info(f"æ•´æ•°IDæŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ° {len(int_docs)} æ¡è®°å½•")
                        for doc in int_docs:
                            original_str = int_to_str.get(doc["_id"])
                            if original_str:
                                id_mappings[original_str] = str(doc["_id"])
                        docs.extend(int_docs)
                        
            except Exception as int_error:
                logging.warning(f"æ•´æ•°IDè½¬æ¢å¤±è´¥: {int_error}")
        
        # æ„å»ºIDåˆ°æ–‡æ¡£çš„æ˜ å°„
        id2doc = {}
        for doc in docs:
            doc_id_str = str(doc["_id"])
            id2doc[doc_id_str] = doc
            # å¦‚æœæœ‰æ˜ å°„å…³ç³»ï¼Œä¹Ÿæ·»åŠ åŸå§‹IDçš„æ˜ å°„
            for milvus_id, mongo_id in id_mappings.items():
                if mongo_id == doc_id_str:
                    id2doc[milvus_id] = doc
        
        # æŒ‰Milvusè¿”å›é¡ºåºæ„å»ºç»“æœ
        enriched = []
        missing_count = 0
        missing_ids_list = []
        
        for id_, score in milvus_results:
            doc = id2doc.get(id_)
            
            if doc:
                enriched.append(SearchResult(
                    id=id_,
                    score=score,
                    text=doc.get("text", ""),
                    metadata=doc.get("metadata", {})
                ))
            else:
                missing_count += 1
                missing_ids_list.append(id_)
                logging.warning(f"MongoDBä¸­æœªæ‰¾åˆ°ID: {id_} (ç±»å‹: {type(id_).__name__})")
                # ä¿ç•™è¯¥ç»“æœä½†æ ‡è®°ä¸ºç¼ºå¤±
                enriched.append(SearchResult(
                    id=id_,
                    score=score,
                    text="[æ•°æ®ç¼ºå¤±]",
                    metadata={
                        "_missing": True,
                        "_milvus_id": id_,
                        "_note": "è¯¥è®°å½•å­˜åœ¨äºMilvusä½†åœ¨MongoDBä¸­æ‰¾ä¸åˆ°"
                    }
                ))
        
        if stats is not None:
            stats["mongo_time"] = time.time() - mongo_start
            stats["mongo_found"] = len(docs)
            stats["mongo_missing"] = missing_count
            stats["missing_ids"] = missing_ids_list[:5]  # åªè®°å½•å‰5ä¸ª
        
        if missing_count > 0:
            logging.error(f"âš ï¸ æœ‰ {missing_count}/{len(milvus_results)} æ¡è®°å½•åœ¨MongoDBä¸­ç¼ºå¤±")
            logging.error(f"ç¤ºä¾‹ç¼ºå¤±ID: {missing_ids_list[:3]}")
        
        return enriched
        
    except Exception as e:
        logging.error(f"MongoDBæŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise MongoQueryError(f"å…ƒæ•°æ®æŸ¥è¯¢å¤±è´¥: {str(e)}") from e


def _apply_filter(
    results: List[SearchResult],
    filter_mode: str,
    filter_threshold: float,
    stats: Optional[Dict]
) -> List[Dict[str, Any]]:
    """åº”ç”¨ç›¸ä¼¼åº¦/è·ç¦»è¿‡æ»¤"""
    if filter_mode == "similarity":
        # COSINEç›¸ä¼¼åº¦: å€¼è¶Šå¤§è¶Šç›¸ä¼¼ï¼Œä¿ç•™ >= threshold
        filtered = [r for r in results if r.score >= filter_threshold]
    else:  # distance
        # è·ç¦»: å€¼è¶Šå°è¶Šç›¸ä¼¼ï¼Œä¿ç•™ <= threshold
        filtered = [r for r in results if r.score <= filter_threshold]
    
    if stats is not None:
        stats["before_filter"] = len(results)
        stats["after_filter"] = len(filtered)
        stats["filtered_out"] = len(results) - len(filtered)
    
    return [r.to_dict() for r in filtered]


# ============================================================
# MongoDB è¾…åŠ©å‡½æ•°ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
# ============================================================

def auto_connect_mongodb(mongodb_config):
    """
    åˆå§‹åŒ– MongoDB è¿æ¥ï¼Œè¿”å›ä¸‰å…ƒç»„ï¼š(è¿æ¥æˆåŠŸ, é”™è¯¯æ¶ˆæ¯, clientå¯¹è±¡)
    å¤–éƒ¨è°ƒç”¨æ— éœ€ç›´æ¥å†™å…¥ session_stateï¼Œç”±ä¸»å…¥å£ç»Ÿä¸€èµ‹å€¼å¯ä»¥é˜²æ­¢è¦†ç›–ã€‚
    """
    if not mongodb_config or not mongodb_config.get("host"):
        return False, "ç¼ºå°‘ MongoDB é…ç½®", None

    try:
        username = mongodb_config.get("username", "")
        password = mongodb_config.get("password", "")
        host = mongodb_config.get("host", "localhost")
        port = mongodb_config.get("port", 27017)
        db_name = mongodb_config.get("db_name", "textdb")
        col_name = mongodb_config.get("col_name", "metadata")

        if username and password:
            uri = f"mongodb://{username}:{password}@{host}:{port}/{db_name}?authSource=admin"
        else:
            uri = f"mongodb://{host}:{port}/"

        client = MongoClient(uri, serverSelectionTimeoutMS=3000)
        db = client[db_name]
        col = db[col_name]
        _ = col.estimated_document_count()
        return True, None, client
    except Exception as e:
        return False, str(e), None


def get_mongodb_stats(mongodb_client, mongodb_config):
    """
    ç»Ÿè®¡MongoDBä¸»ä¸šåŠ¡é›†åˆçš„çŠ¶æ€ä¸æ•°æ®é‡ã€‚
    - è¾“å…¥: mongodb_client (pymongo.MongoClientå¯¹è±¡), mongodb_configï¼ˆdicté…ç½®ï¼‰
    - è¿”å›: dict {connected: bool, error: str or None, count: int, sample_texts: list, vector_info: str, vector_size: float}
    """
    stats = {
        "connected": False,
        "error": None,
        "count": 0,
        "sample_texts": [],
        "vector_info": "N/A",
        "vector_size": 0.0
    }

    if not mongodb_client or not mongodb_config:
        stats["error"] = "ç¼ºå°‘è¿æ¥å¯¹è±¡æˆ–é…ç½®"
        return stats

    try:
        db = mongodb_client[mongodb_config.get("db_name", "textdb")]
        col = db[mongodb_config.get("col_name", "metadata")]
        stats["count"] = col.count_documents({})
        stats["connected"] = True

        sample_docs = list(col.find({}, {"text": 1}).limit(10))
        stats["sample_texts"] = [doc.get("text", "") for doc in sample_docs]

        # æ£€æŸ¥å‘é‡å­—æ®µ
        vector_sample = col.find_one({"vector": {"$exists": True}}, {"vector": 1})
        if vector_sample and vector_sample.get("vector") is not None:
            sample_vector = np.array(vector_sample["vector"])
            stats["vector_info"] = sample_vector.shape[0] if sample_vector.ndim > 0 else "N/A"
            stats["vector_size"] = sample_vector.nbytes / 1024 / 1024
    except Exception as e:
        stats["error"] = str(e)

    return stats


def get_mongodb_data(mongodb_config):
    """ä»MongoDBè¯»å–æ–‡æœ¬ä¸å‘é‡æ•°æ®ï¼Œå¹¶ç»Ÿè®¡"""
    host = mongodb_config.get('host', 'localhost')
    port = mongodb_config.get('port', 27017)
    db_name = mongodb_config.get('db_name', '')
    col_name = mongodb_config.get('col_name', 'texts')
    user = mongodb_config.get('username')
    pwd = mongodb_config.get('password')
    auth = f"{user}:{pwd}@" if user and pwd else ""
    mongo_uri = f"mongodb://{auth}{host}:{port}"
    results = {
        "connected": False,
        "count": 0,
        "texts": [],
        "vectors": None,
        "error": None
    }
    try:
        client = MongoClient(mongo_uri, serverSelectionTimeoutMS=3000)
        db = client[db_name]
        col = db[col_name]
        docs = list(col.find({}, {"_id": 0}))
        texts = [doc.get("text", "") for doc in docs]
        vectors = np.array([doc["vector"] for doc in docs if "vector" in doc])
        doc_count = col.estimated_document_count()
        data_loaded = len(texts) > 0
        results.update({
            "connected": True,
            "count": doc_count,
            "texts": texts,
            "vectors": vectors if data_loaded else None,
        })
    except Exception as e:
        results["error"] = str(e)
    return results